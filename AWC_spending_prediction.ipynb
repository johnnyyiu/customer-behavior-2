{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Behaivor Prediction (2) - Monthly Spending\n",
    "\n",
    "## Overview\n",
    "In 1998, the Adventure Works Cycles company collected a large volume of data about their existing customers, including demographic features and information about purchases they have made. The company is particularly interested in analyzing customer data to determine any apparent relationships between demographic features known about the customers and the likelihood of a customer purchasing a bike. Additionally, the analysis should endeavor to determine whether a customer's average monthly spend with the company can be predicted from known customer characteristics.\n",
    "\n",
    "## Goal\n",
    "The goal is to build a regression model to predict customers' monthly spending.\n",
    "\n",
    "## Data\n",
    "The training and test datasets are retrieved from [Microsoft Learning](https://github.com/MicrosoftLearning).\n",
    "\n",
    "## Model\n",
    "We are adopting a simple linear regression model to predict customers' monthly spending. Evaluated with cross-validation on the training data, the simple model gives an R^2 of **0.9464**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.stats as ss\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "custs = pd.read_csv('D:\\\\Users\\\\user\\\\Desktop\\\\MPP DS Cert\\\\DAT275x - Principles of Machine Learning Python Edition\\\\AdvWorksCusts.csv')\n",
    "avgms = pd.read_csv('D:\\\\Users\\\\user\\\\Desktop\\\\MPP DS Cert\\\\DAT275x - Principles of Machine Learning Python Edition\\\\AW_AveMonthSpend.csv')\n",
    "bikeby = pd.read_csv('D:\\\\Users\\\\user\\\\Desktop\\\\MPP DS Cert\\\\DAT275x - Principles of Machine Learning Python Edition\\\\AW_BikeBuyer.csv')\n",
    "AW_test = pd.read_csv('D:\\\\Users\\\\user\\\\Desktop\\\\MPP DS Cert\\\\DAT275x - Principles of Machine Learning Python Edition\\\\AW_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP DUPLICATES\n",
    "custs = custs.drop_duplicates(keep = 'last')\n",
    "avgms = avgms.drop_duplicates(keep = 'last')\n",
    "bikeby = bikeby.drop_duplicates(keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE CSVS\n",
    "custs = pd.merge(custs, avgms, on='CustomerID')\n",
    "custs = pd.merge(custs, bikeby, on='CustomerID')\n",
    "# print(custs.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CustomerID', 'Title', 'FirstName', 'MiddleName', 'LastName', 'Suffix',\n",
       "       'AddressLine1', 'AddressLine2', 'City', 'StateProvinceName',\n",
       "       'CountryRegionName', 'PostalCode', 'PhoneNumber', 'BirthDate',\n",
       "       'Education', 'Occupation', 'Gender', 'MaritalStatus', 'HomeOwnerFlag',\n",
       "       'NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren',\n",
       "       'YearlyIncome', 'AveMonthSpend', 'BikeBuyer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        32.0\n",
      "1        33.0\n",
      "2        32.0\n",
      "3        30.0\n",
      "4        29.0\n",
      "5        32.0\n",
      "6        32.0\n",
      "7        34.0\n",
      "8        33.0\n",
      "9        34.0\n",
      "10       34.0\n",
      "11       34.0\n",
      "12       30.0\n",
      "13       29.0\n",
      "14       30.0\n",
      "15       19.0\n",
      "16       19.0\n",
      "17       20.0\n",
      "18       19.0\n",
      "19       19.0\n",
      "20       19.0\n",
      "21       52.0\n",
      "22       52.0\n",
      "23       51.0\n",
      "24       52.0\n",
      "25       50.0\n",
      "26       51.0\n",
      "27       50.0\n",
      "28       51.0\n",
      "29       50.0\n",
      "         ... \n",
      "16441    20.0\n",
      "16442    21.0\n",
      "16443    54.0\n",
      "16444    36.0\n",
      "16445    37.0\n",
      "16446    37.0\n",
      "16447    37.0\n",
      "16448    38.0\n",
      "16449    38.0\n",
      "16450    38.0\n",
      "16451    38.0\n",
      "16452    38.0\n",
      "16453    39.0\n",
      "16454    38.0\n",
      "16455    39.0\n",
      "16456    39.0\n",
      "16457    37.0\n",
      "16458    38.0\n",
      "16459    39.0\n",
      "16460    41.0\n",
      "16461    42.0\n",
      "16462    43.0\n",
      "16463    46.0\n",
      "16464    50.0\n",
      "16465    41.0\n",
      "16466    33.0\n",
      "16467    62.0\n",
      "16468    58.0\n",
      "16469    51.0\n",
      "16470    53.0\n",
      "Name: Age, Length: 16471, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#CREATE AGE\n",
    "custs['Today'] = pd.Timestamp(\"1998-01-01\")\n",
    "custs['BirthDate'] = pd.to_datetime(custs['BirthDate'])\n",
    "custs['Age'] = custs['Today'] - custs['BirthDate']\n",
    "custs['Age'] = custs['Age']/np.timedelta64(1,'Y')\n",
    "custs['Age'] = custs['Age'].round()\n",
    "\n",
    "#CREATE AGE for test data\n",
    "AW_test['Today'] = pd.Timestamp(\"1998-01-01\")\n",
    "AW_test['BirthDate'] = pd.to_datetime(AW_test['BirthDate'])\n",
    "AW_test['Age'] = AW_test['Today'] - AW_test['BirthDate']\n",
    "AW_test['Age'] = AW_test['Age']/np.timedelta64(1,'Y')\n",
    "AW_test['Age'] = AW_test['Age'].round()\n",
    "\n",
    "print(custs['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16471, 23)\n",
      "<bound method NDFrame.head of        CustomerID   FirstName    LastName                 AddressLine1  \\\n",
      "0           11000         Jon        Yang              3761 N. 14th St   \n",
      "1           11001      Eugene       Huang                   2243 W St.   \n",
      "2           11002       Ruben      Torres             5844 Linden Land   \n",
      "3           11003     Christy         Zhu             1825 Village Pl.   \n",
      "4           11004   Elizabeth     Johnson          7553 Harness Circle   \n",
      "5           11005       Julio        Ruiz          7305 Humphrey Drive   \n",
      "6           11006       Janet     Alvarez                2612 Berry Dr   \n",
      "7           11007       Marco       Mehta             942 Brook Street   \n",
      "8           11008         Rob     Verhoff             624 Peabody Road   \n",
      "9           11009     Shannon     Carlson          3839 Northgate Road   \n",
      "10          11010   Jacquelyn      Suarez          7800 Corrinne Court   \n",
      "11          11011      Curtis          Lu                 1224 Shoenic   \n",
      "12          11012      Lauren      Walker            4785 Scott Street   \n",
      "13          11013         Ian     Jenkins             7902 Hudson Ave.   \n",
      "14          11014      Sydney     Bennett              9011 Tank Drive   \n",
      "15          11015       Chloe       Young         244 Willow Pass Road   \n",
      "16          11016       Wyatt        Hill          9666 Northridge Ct.   \n",
      "17          11019        Luke         Lal              7832 Landing Dr   \n",
      "18          11020      Jordan        King                7156 Rose Dr.   \n",
      "19          11023        Seth     Edwards            4499 Valley Crest   \n",
      "20          11024     Russell         Xie            8734 Oxford Place   \n",
      "21          11025   Alejandro        Beck    2596 Franklin Canyon Road   \n",
      "22          11026      Harold         Sai               8211 Leeds Ct.   \n",
      "23          11027      Jessie        Zhao           213 Valencia Place   \n",
      "24          11028        Jill     Jimenez            9111 Rose Ann Ave   \n",
      "25          11031     Theresa       Ramos            6465 Detroit Ave.   \n",
      "26          11032      Denise       Stone           626 Bentley Street   \n",
      "27          11033       Jaime        Nath              5927 Rainbow Dr   \n",
      "28          11034       Ebony    Gonzalez            5167 Condor Place   \n",
      "29          11035       Wendy   Dominguez          1873 Mt. Whitney Dr   \n",
      "...           ...         ...         ...                          ...   \n",
      "16441       29464      Eugene         Gao         4581 Coldwater Drive   \n",
      "16442       29465         Roy        Gill      4072 South Hampton Road   \n",
      "16443       29466       Lance     Jimenez           Auf Der Steige 532   \n",
      "16444       29467      Monica       Mehta             Bundesallee 2461   \n",
      "16445       29468  Jacqueline      Morris          6934 Santa Cruz Dr.   \n",
      "16446       29469   Dominique    Saunders            3792 Westwood Ct.   \n",
      "16447       29470      Nathan     Roberts  29, boulevard Beau Marchais   \n",
      "16448       29471        Dana      Ortega        80, rue de Fontfroide   \n",
      "16449       29472       Lacey      Sharma            21, avenue Reille   \n",
      "16450       29473      Carmen      Subram             6467 Buena Vista   \n",
      "16451       29474       Jaime        Raje         Potsdamer Straße 646   \n",
      "16452       29475       Jared        Ward                Erftplatz 876   \n",
      "16453       29476   Elizabeth     Bradley                 Nonnendamm 2   \n",
      "16454       29477        Neil        Ruiz                P.O. Box 9178   \n",
      "16455       29478      Darren     Carlson             5240 Premier Pl.   \n",
      "16456       29479       Tommy        Tang            111, rue Maillard   \n",
      "16457       29480        Nina        Raji            9 Katherine Drive   \n",
      "16458       29481        Ivan        Suri                  Knaackstr 4   \n",
      "16459       29482     Clayton       Zhang       1080, quai de Grenelle   \n",
      "16460       25352     Brandon    Martinez         843 Camino Verde Cr.   \n",
      "16461       13139      Carmen       Perez       1622 Silver Oaks Place   \n",
      "16462       18651      Isaiah    Mitchell            5014 Steele Drive   \n",
      "16463       24992       Faith      Bryant  6267 Morello Heights Circle   \n",
      "16464       11442      Joseph      Harris       8, rue des Vendangeurs   \n",
      "16465       18487       Tasha        Nath             4992 Yorba Linda   \n",
      "16466       13121     Latasha     Jimenez               7259 Birchwood   \n",
      "16467       26100       James  Ptaszynski              7345 Kenwal Rd.   \n",
      "16468       11328      Julian     Griffin          7398 Withersed Lane   \n",
      "16469       23077      Marvin   Hernandez               1019 Book Road   \n",
      "16470       18982        Kyle       Baker              2118 Little Dr.   \n",
      "\n",
      "                     City    StateProvinceName CountryRegionName PostalCode  \\\n",
      "0             Rockhampton           Queensland         Australia       4700   \n",
      "1                 Seaford             Victoria         Australia       3198   \n",
      "2                  Hobart             Tasmania         Australia       7001   \n",
      "3              North Ryde      New South Wales         Australia       2113   \n",
      "4              Wollongong      New South Wales         Australia       2500   \n",
      "5           East Brisbane           Queensland         Australia       4169   \n",
      "6              Matraville      New South Wales         Australia       2036   \n",
      "7             Warrnambool             Victoria         Australia       3280   \n",
      "8                 Bendigo             Victoria         Australia       3550   \n",
      "9              Hervey Bay           Queensland         Australia       4655   \n",
      "10          East Brisbane           Queensland         Australia       4169   \n",
      "11          East Brisbane           Queensland         Australia       4169   \n",
      "12              Bremerton           Washington     United States      98312   \n",
      "13                Lebanon               Oregon     United States      97355   \n",
      "14                Redmond           Washington     United States      98052   \n",
      "15                Burbank           California     United States      91502   \n",
      "16         Imperial Beach           California     United States      91932   \n",
      "17                Langley     British Columbia            Canada    V3A 4R2   \n",
      "18              Metchosin     British Columbia            Canada         V9   \n",
      "19             Bellflower           California     United States      90706   \n",
      "20                Concord           California     United States      94519   \n",
      "21              Hawthorne           Queensland         Australia       4171   \n",
      "22               Goulburn      New South Wales         Australia       2580   \n",
      "23            Warrnambool             Victoria         Australia       3280   \n",
      "24           St. Leonards      New South Wales         Australia       2065   \n",
      "25             Matraville      New South Wales         Australia       2036   \n",
      "26              Melbourne             Victoria         Australia       3000   \n",
      "27          Milsons Point      New South Wales         Australia       2061   \n",
      "28           North Sydney      New South Wales         Australia       2055   \n",
      "29             Cranbourne             Victoria         Australia       3977   \n",
      "...                   ...                  ...               ...        ...   \n",
      "16441         Rockhampton           Queensland         Australia       4700   \n",
      "16442          Matraville      New South Wales         Australia       2036   \n",
      "16443            Solingen  Nordrhein-Westfalen           Germany      42651   \n",
      "16444     Sulzbach Taunus             Saarland           Germany      66272   \n",
      "16445          Cheltenham              England    United Kingdom       GL50   \n",
      "16446                Oxon              England    United Kingdom   OX16 8RS   \n",
      "16447              Drancy    Seine Saint Denis            France      93700   \n",
      "16448           Dunkerque                 Nord            France      59140   \n",
      "16449               Paris        Seine (Paris)            France      75003   \n",
      "16450              Oxford              England    United Kingdom        OX1   \n",
      "16451         Saarbrücken             Saarland           Germany      66001   \n",
      "16452             Hamburg              Hamburg           Germany      20354   \n",
      "16453             Hamburg              Hamburg           Germany      20354   \n",
      "16454              London              England    United Kingdom    W10 6BL   \n",
      "16455      Stoke-on-Trent              England    United Kingdom       AS23   \n",
      "16456          Versailles              Yveline            France      78000   \n",
      "16457              London              England    United Kingdom   SW19 3RU   \n",
      "16458                 Hof               Bayern           Germany      95010   \n",
      "16459          Saint Ouen    Charente-Maritime            France      17490   \n",
      "16460         Lake Oswego               Oregon     United States      97034   \n",
      "16461           Lane Cove      New South Wales         Australia       1597   \n",
      "16462            Lynnwood           Washington     United States      98036   \n",
      "16463         Chula Vista           California     United States      91910   \n",
      "16464  Tremblay-en-France    Seine Saint Denis            France      93290   \n",
      "16465             Sunbury             Victoria         Australia       3429   \n",
      "16466              Melton             Victoria         Australia       3337   \n",
      "16467             Shawnee     British Columbia            Canada    V8Z 4N5   \n",
      "16468              Newton     British Columbia            Canada     V2L3W8   \n",
      "16469              Rhodes      New South Wales         Australia       2138   \n",
      "16470            Kirkland           Washington     United States      98033   \n",
      "\n",
      "               PhoneNumber  BirthDate  ... MaritalStatus HomeOwnerFlag  \\\n",
      "0      1 (11) 500 555-0162 1966-04-08  ...             M             1   \n",
      "1      1 (11) 500 555-0110 1965-05-14  ...             S             0   \n",
      "2      1 (11) 500 555-0184 1965-08-12  ...             M             1   \n",
      "3      1 (11) 500 555-0162 1968-02-15  ...             S             0   \n",
      "4      1 (11) 500 555-0131 1968-08-08  ...             S             1   \n",
      "5      1 (11) 500 555-0151 1965-08-05  ...             S             1   \n",
      "6      1 (11) 500 555-0184 1965-12-06  ...             S             1   \n",
      "7      1 (11) 500 555-0126 1964-05-09  ...             M             1   \n",
      "8      1 (11) 500 555-0164 1964-07-07  ...             S             1   \n",
      "9      1 (11) 500 555-0110 1964-04-01  ...             S             0   \n",
      "10     1 (11) 500 555-0169 1964-02-06  ...             S             0   \n",
      "11     1 (11) 500 555-0117 1963-11-04  ...             M             1   \n",
      "12            717-555-0164 1968-01-18  ...             M             1   \n",
      "13            817-555-0185 1968-08-06  ...             M             1   \n",
      "14            431-555-0156 1968-05-09  ...             S             0   \n",
      "15            208-555-0142 1979-02-27  ...             S             0   \n",
      "16            135-555-0171 1979-04-28  ...             M             1   \n",
      "17            262-555-0112 1978-03-07  ...             S             0   \n",
      "18            550-555-0163 1978-09-20  ...             S             0   \n",
      "19            452-555-0188 1978-10-11  ...             M             1   \n",
      "20            746-555-0186 1978-09-17  ...             M             1   \n",
      "21     1 (11) 500 555-0178 1945-12-23  ...             M             1   \n",
      "22     1 (11) 500 555-0131 1946-04-03  ...             S             0   \n",
      "23     1 (11) 500 555-0184 1946-12-07  ...             M             1   \n",
      "24     1 (11) 500 555-0116 1946-04-11  ...             M             1   \n",
      "25     1 (11) 500 555-0195 1947-08-22  ...             M             1   \n",
      "26     1 (11) 500 555-0169 1947-06-11  ...             M             1   \n",
      "27     1 (11) 500 555-0137 1947-09-23  ...             M             1   \n",
      "28     1 (11) 500 555-0136 1947-06-19  ...             M             1   \n",
      "29     1 (11) 500 555-0177 1948-02-24  ...             M             1   \n",
      "...                    ...        ...  ...           ...           ...   \n",
      "16441  1 (11) 500 555-0177 1977-09-05  ...             S             0   \n",
      "16442  1 (11) 500 555-0110 1977-06-19  ...             S             1   \n",
      "16443  1 (11) 500 555-0126 1943-11-26  ...             M             1   \n",
      "16444  1 (11) 500 555-0121 1961-10-16  ...             M             1   \n",
      "16445  1 (11) 500 555-0131 1961-06-27  ...             M             0   \n",
      "16446  1 (11) 500 555-0172 1961-04-26  ...             M             0   \n",
      "16447  1 (11) 500 555-0111 1960-08-25  ...             S             0   \n",
      "16448  1 (11) 500 555-0148 1960-03-26  ...             S             0   \n",
      "16449  1 (11) 500 555-0178 1960-03-14  ...             M             0   \n",
      "16450  1 (11) 500 555-0129 1960-05-22  ...             S             0   \n",
      "16451  1 (11) 500 555-0174 1959-10-04  ...             M             0   \n",
      "16452  1 (11) 500 555-0135 1959-09-23  ...             S             0   \n",
      "16453  1 (11) 500 555-0177 1959-07-03  ...             M             0   \n",
      "16454  1 (11) 500 555-0114 1959-07-06  ...             M             0   \n",
      "16455  1 (11) 500 555-0132 1959-05-25  ...             S             1   \n",
      "16456  1 (11) 500 555-0136 1958-07-04  ...             M             1   \n",
      "16457  1 (11) 500 555-0146 1960-11-10  ...             S             1   \n",
      "16458  1 (11) 500 555-0144 1960-01-05  ...             S             0   \n",
      "16459  1 (11) 500 555-0137 1959-03-05  ...             M             1   \n",
      "16460         327-555-0193 1957-02-14  ...             M             0   \n",
      "16461  1 (11) 500 555-0195 1956-02-09  ...             S             0   \n",
      "16462         694-555-0195 1955-05-06  ...             M             0   \n",
      "16463         154-555-0170 1952-03-12  ...             M             1   \n",
      "16464  1 (11) 500 555-0116 1947-11-14  ...             M             1   \n",
      "16465  1 (11) 500 555-0159 1956-10-10  ...             S             0   \n",
      "16466  1 (11) 500 555-0118 1965-03-22  ...             M             1   \n",
      "16467         127-555-0194 1936-04-02  ...             S             1   \n",
      "16468         636-555-0197 1940-01-01  ...             M             1   \n",
      "16469  1 (11) 500 555-0112 1946-10-20  ...             M             1   \n",
      "16470         685-555-0144 1945-04-07  ...             S             1   \n",
      "\n",
      "      NumberCarsOwned NumberChildrenAtHome  TotalChildren  YearlyIncome  \\\n",
      "0                   0                    0              2        137947   \n",
      "1                   1                    3              3        101141   \n",
      "2                   1                    3              3         91945   \n",
      "3                   1                    0              0         86688   \n",
      "4                   4                    5              5         92771   \n",
      "5                   1                    0              0        103199   \n",
      "6                   1                    0              0         84756   \n",
      "7                   2                    3              3        109759   \n",
      "8                   3                    4              4         88005   \n",
      "9                   1                    0              0        106399   \n",
      "10                  1                    0              0         81294   \n",
      "11                  4                    4              4         94029   \n",
      "12                  2                    0              2         99245   \n",
      "13                  3                    0              2        115859   \n",
      "14                  3                    0              3        105157   \n",
      "15                  1                    0              0         40011   \n",
      "16                  1                    0              0         46808   \n",
      "17                  2                    0              0         49455   \n",
      "18                  2                    0              0         43857   \n",
      "19                  1                    0              0         50046   \n",
      "20                  2                    0              0         91276   \n",
      "21                  2                    1              2         24334   \n",
      "22                  2                    0              2         61905   \n",
      "23                  2                    0              2         49349   \n",
      "24                  2                    0              2         44068   \n",
      "25                  2                    0              4         18843   \n",
      "26                  2                    0              4         15861   \n",
      "27                  2                    0              4         35822   \n",
      "28                  2                    0              4         29017   \n",
      "29                  2                    1              2         11721   \n",
      "...               ...                  ...            ...           ...   \n",
      "16441               0                    1              1         12002   \n",
      "16442               0                    0              0         22109   \n",
      "16443               0                    0              1         59132   \n",
      "16444               0                    0              4         75167   \n",
      "16445               0                    0              4         62297   \n",
      "16446               0                    0              3         65669   \n",
      "16447               1                    1              1         28464   \n",
      "16448               1                    1              1         28506   \n",
      "16449               1                    1              1         11848   \n",
      "16450               0                    1              1         20048   \n",
      "16451               1                    0              2         24761   \n",
      "16452               1                    0              2         29938   \n",
      "16453               1                    0              2         18670   \n",
      "16454               1                    0              2         22992   \n",
      "16455               0                    0              3         45986   \n",
      "16456               0                    0              1         80049   \n",
      "16457               0                    0              3         60417   \n",
      "16458               0                    0              3         66653   \n",
      "16459               0                    0              3         59736   \n",
      "16460               2                    1              2         18570   \n",
      "16461               1                    0              1         59605   \n",
      "16462               2                    0              1         55291   \n",
      "16463               2                    1              2         86140   \n",
      "16464               2                    0              5        103335   \n",
      "16465               2                    0              2         72037   \n",
      "16466               4                    5              5        101542   \n",
      "16467               2                    0              3         46549   \n",
      "16468               2                    0              5        133053   \n",
      "16469               2                    0              4         31930   \n",
      "16470               2                    0              4         59382   \n",
      "\n",
      "       AveMonthSpend  BikeBuyer      Today   Age  \n",
      "0                 89          0 1998-01-01  32.0  \n",
      "1                117          1 1998-01-01  33.0  \n",
      "2                123          0 1998-01-01  32.0  \n",
      "3                 50          0 1998-01-01  30.0  \n",
      "4                 95          1 1998-01-01  29.0  \n",
      "5                 78          1 1998-01-01  32.0  \n",
      "6                 54          1 1998-01-01  32.0  \n",
      "7                130          1 1998-01-01  34.0  \n",
      "8                 85          1 1998-01-01  33.0  \n",
      "9                 74          0 1998-01-01  34.0  \n",
      "10                49          0 1998-01-01  34.0  \n",
      "11               146          1 1998-01-01  34.0  \n",
      "12                55          1 1998-01-01  30.0  \n",
      "13                84          0 1998-01-01  29.0  \n",
      "14                49          0 1998-01-01  30.0  \n",
      "15                39          0 1998-01-01  19.0  \n",
      "16                68          0 1998-01-01  19.0  \n",
      "17                64          1 1998-01-01  20.0  \n",
      "18                64          0 1998-01-01  19.0  \n",
      "19                71          0 1998-01-01  19.0  \n",
      "20                77          0 1998-01-01  19.0  \n",
      "21                70          0 1998-01-01  52.0  \n",
      "22                63          0 1998-01-01  52.0  \n",
      "23                76          0 1998-01-01  51.0  \n",
      "24                43          0 1998-01-01  52.0  \n",
      "25                43          0 1998-01-01  50.0  \n",
      "26                42          0 1998-01-01  51.0  \n",
      "27                58          0 1998-01-01  50.0  \n",
      "28                39          0 1998-01-01  51.0  \n",
      "29                50          0 1998-01-01  50.0  \n",
      "...              ...        ...        ...   ...  \n",
      "16441             67          0 1998-01-01  20.0  \n",
      "16442             64          0 1998-01-01  21.0  \n",
      "16443             64          0 1998-01-01  54.0  \n",
      "16444             57          0 1998-01-01  36.0  \n",
      "16445             53          0 1998-01-01  37.0  \n",
      "16446             56          0 1998-01-01  37.0  \n",
      "16447             69          1 1998-01-01  37.0  \n",
      "16448             49          0 1998-01-01  38.0  \n",
      "16449             45          0 1998-01-01  38.0  \n",
      "16450             43          0 1998-01-01  38.0  \n",
      "16451             64          0 1998-01-01  38.0  \n",
      "16452             61          0 1998-01-01  38.0  \n",
      "16453             48          0 1998-01-01  39.0  \n",
      "16454             67          0 1998-01-01  38.0  \n",
      "16455             65          0 1998-01-01  39.0  \n",
      "16456             77          0 1998-01-01  39.0  \n",
      "16457             48          1 1998-01-01  37.0  \n",
      "16458             65          0 1998-01-01  38.0  \n",
      "16459             72          0 1998-01-01  39.0  \n",
      "16460             74          0 1998-01-01  41.0  \n",
      "16461             49          1 1998-01-01  42.0  \n",
      "16462             73          0 1998-01-01  43.0  \n",
      "16463             70          0 1998-01-01  46.0  \n",
      "16464             81          0 1998-01-01  50.0  \n",
      "16465             49          0 1998-01-01  41.0  \n",
      "16466            101          0 1998-01-01  33.0  \n",
      "16467             46          0 1998-01-01  62.0  \n",
      "16468             79          0 1998-01-01  58.0  \n",
      "16469             65          0 1998-01-01  51.0  \n",
      "16470             68          0 1998-01-01  53.0  \n",
      "\n",
      "[16471 rows x 23 columns]>\n"
     ]
    }
   ],
   "source": [
    "#DROP COLUMNS\n",
    "custs.drop('Title', axis = 1, inplace = True)\n",
    "custs.drop('MiddleName', axis = 1, inplace = True)\n",
    "custs.drop('Suffix', axis = 1, inplace = True)\n",
    "custs.drop('AddressLine2', axis = 1, inplace = True)\n",
    "\n",
    "print(custs.shape)\n",
    "print(custs.head)\n",
    "\n",
    "#CHECK FOR CLASS IMBALANCE\n",
    "bb_counts = custs[['CustomerID', 'BikeBuyer']].groupby('BikeBuyer').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create label\n",
    "labels = np.array(custs['AveMonthSpend'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16471, 22)\n",
      "[[1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0.]]\n",
      "['Australia' 'United States' 'Canada' 'Germany' 'United Kingdom' 'France']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Create feature array\n",
    "def encode_string(cat_features):\n",
    "    ## First encode the strings to numeric categories\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    enc.fit(cat_features)\n",
    "    enc_cat_features = enc.transform(cat_features)\n",
    "    ## Now, apply one hot encoding\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    encoded = ohe.fit(enc_cat_features.reshape(-1,1))\n",
    "    return encoded.transform(enc_cat_features.reshape(-1,1)).toarray()\n",
    "\n",
    "categorical_columns = ['Education', 'Occupation', 'Gender', 'MaritalStatus', 'HomeOwnerFlag']\n",
    "\n",
    "Features = encode_string(custs['CountryRegionName'])\n",
    "for col in categorical_columns:\n",
    "    temp = encode_string(custs[col])\n",
    "    Features = np.concatenate([Features, temp], axis = 1)\n",
    "\n",
    "\n",
    "print(Features.shape)\n",
    "print(Features[:2, :])\n",
    "print(custs['CountryRegionName'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge the encoded categorical features with numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00 2.00000e+00 0.00000e+00\n",
      "  5.00000e+00 8.69310e+04 5.30000e+01]\n",
      " [0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 2.00000e+00 2.00000e+00\n",
      "  4.00000e+00 1.00125e+05 3.30000e+01]]\n",
      "(500, 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Concatenate with numeric features\n",
    "Features = np.concatenate([Features, np.array(custs[\n",
    "                                                  ['NumberCarsOwned', 'NumberChildrenAtHome',\n",
    "                                                      'TotalChildren', 'YearlyIncome', 'Age']\n",
    "                                              ])], axis = 1)\n",
    "# print(Features.shape)\n",
    "# print(Features[:2, :])\n",
    "\n",
    "#Create feature array for AW_Test and concatenate numeric features\n",
    "AW_test_Features = encode_string(AW_test['CountryRegionName'])\n",
    "for col in categorical_columns:\n",
    "    temp = encode_string(AW_test[col])\n",
    "    AW_test_Features = np.concatenate([AW_test_Features, temp], axis = 1)\n",
    "\n",
    "AW_test_Features = np.concatenate([AW_test_Features, np.array(AW_test[\n",
    "                                                  ['NumberCarsOwned', 'NumberChildrenAtHome',\n",
    "                                                      'TotalChildren', 'YearlyIncome', 'Age']\n",
    "                                              ])], axis = 1)\n",
    "\n",
    "print(AW_test_Features[:2,:])\n",
    "print(AW_test_Features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "nr.seed(8585)\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 500)\n",
    "X_train = Features[indx[0],:]\n",
    "y_train = np.ravel(labels[indx[0]])\n",
    "X_test = AW_test_Features\n",
    "#y_test = np.ravel(labels[indx[1]]) #no y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data\n",
    "scaler = preprocessing.StandardScaler().fit(X_train[:,22:])\n",
    "X_train[:,22:] = scaler.transform(X_train[:,22:])\n",
    "X_test[:,22:] = scaler.transform(X_test[:,22:])\n",
    "# print(X_train[:2,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-76950206890290.66\n",
      "[-5.88934922e+11 -5.88934922e+11 -5.88934922e+11 -5.88934922e+11\n",
      " -5.88934922e+11 -5.88934922e+11  3.80570350e+13  3.80570350e+13\n",
      "  3.80570350e+13  3.80570350e+13  3.80570350e+13  3.61794583e+13\n",
      "  3.61794583e+13  3.61794583e+13  3.61794583e+13  3.61794583e+13\n",
      " -1.94736266e+12 -1.94736266e+12  1.55723440e+12  1.55723440e+12\n",
      "  3.69277676e+12  3.69277676e+12 -4.20776367e-01  1.62786560e+01\n",
      "  6.30022049e-01  8.61718750e+00 -1.49377441e+00]\n",
      "[ 42.71875 107.       48.71875]\n"
     ]
    }
   ],
   "source": [
    "#Construct the linear regression model\n",
    "lin_mod = linear_model.LinearRegression()\n",
    "lin_mod.fit(X_train, y_train)\n",
    "print(lin_mod.intercept_)\n",
    "print(lin_mod.coef_)\n",
    "y_score = lin_mod.predict(X_test)\n",
    "print(y_score[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cross validation folds\n",
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_r2(model, X=X_train):\n",
    "    r2 = cross_val_score(model, X_train, y_train, scoring=\"r2\", cv=kf)\n",
    "    return (r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_mod: 0.9464 (0.0021)\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "score = cv_r2(lin_mod)\n",
    "print(\"lin_mod: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['lin_mod'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export result as csv file\n",
    "# pd.DataFrame(y_score).to_csv(\"regression_test_result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
